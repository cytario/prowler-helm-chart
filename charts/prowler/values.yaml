# This is to override the chart name.
nameOverride: ""
fullnameOverride: ""

# External secret names for PostgreSQL and Valkey connections.
# These secrets must exist in the release namespace before installing the chart.
# Override these if you use External Secrets Operator, Sealed Secrets, or any
# tool that creates secrets with custom names.
externalSecrets:
  postgres:
    # Name of the Kubernetes Secret containing PostgreSQL connection details
    secretName: prowler-postgres-secret
  valkey:
    # Name of the Kubernetes Secret containing Valkey/Redis connection details
    secretName: prowler-valkey-secret

# External PostgreSQL and Valkey secrets are required
# Create secrets with the following keys before installing:
#
# PostgreSQL secret (see externalSecrets.postgres.secretName):
#   POSTGRES_HOST
#   POSTGRES_PORT
#   POSTGRES_ADMIN_USER
#   POSTGRES_ADMIN_PASSWORD
#   POSTGRES_USER
#   POSTGRES_PASSWORD
#   POSTGRES_DB
#
# Valkey secret (see externalSecrets.valkey.secretName):
#   VALKEY_HOST
#   VALKEY_PORT
#   VALKEY_DB
#   VALKEY_PASSWORD (optional)

# Shared storage configuration for scan outputs between API and Worker
# This volume is mounted at /tmp/prowler_api_output in both API and Worker pods
sharedStorage:
  # Type of storage: emptyDir or persistentVolumeClaim
  # emptyDir: Data is lost when pods are deleted (suitable for development)
  # persistentVolumeClaim: Data persists across pod restarts (recommended for production)
  #
  # WARNING: With emptyDir, scan output data is NOT persisted across pod restarts.
  # If an API or Worker pod is evicted, rescheduled, or restarted, any in-progress
  # scan outputs stored in this volume will be lost. For production deployments,
  # use persistentVolumeClaim with ReadWriteMany access mode instead.
  type: emptyDir
  # Configuration for emptyDir type
  emptyDir:
    # Medium can be "" (default, uses node's default storage) or "Memory" (tmpfs, faster but uses RAM)
    medium: ""
    # Size limit for emptyDir (e.g., "1Gi", "500Mi")
    sizeLimit: ""
  # Configuration for persistentVolumeClaim type
  persistentVolumeClaim:
    # Create a new PVC or use an existing one
    create: true
    # Name of existing PVC (only used if create: false)
    existingClaim: ""
    # Storage class name (leave empty to use default)
    storageClassName: ""
    # For API and Worker to share, use ReadWriteMany if available
    # Changing to other will fail
    accessMode: ReadWriteMany
    # Storage size
    size: 10Gi

ui:
  # This will set the replicaset count more information can be found here: https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/
  replicaCount: 2

  # Pod Disruption Budget - ensures high availability during voluntary disruptions
  # More info: https://kubernetes.io/docs/tasks/run-application/configure-pdb/
  podDisruptionBudget:
    enabled: true
    minAvailable: 1
    # maxUnavailable: 1

  # This sets the container image more information can be found here: https://kubernetes.io/docs/concepts/containers/images/
  image:
    repository: prowlercloud/prowler-ui
    # This sets the pull policy for images.
    pullPolicy: IfNotPresent
    # Overrides the image tag whose default is the chart appVersion.
    tag: ""
    # Immutable image reference. When set, takes precedence over tag.
    # Example: sha256:abc123...
    digest: ""

  # This is for the secrets for pulling an image from a private repository more information can be found here: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
  imagePullSecrets: []

  # This section builds out the service account more information can be found here: https://kubernetes.io/docs/concepts/security/service-accounts/
  serviceAccount:
    # Specifies whether a service account should be created
    create: true
    # UI does not need Kubernetes API access
    automount: false
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: ""

  # This is for setting Kubernetes Annotations to a Pod.
  # For more information checkout: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  podAnnotations: {}
  # This is for setting Kubernetes Labels to a Pod.
  # For more information checkout: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  podLabels: {}

  podSecurityContext:
    runAsNonRoot: true
    runAsUser: 1000
    fsGroup: 1000
    seccompProfile:
      type: RuntimeDefault

  securityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: false  # UI needs write access to /app/.next for Next.js
    runAsNonRoot: true
    runAsUser: 1000
    capabilities:
      drop:
        - ALL

  # This is for setting up a service more information can be found here: https://kubernetes.io/docs/concepts/services-networking/service/
  service:
    # This sets the service type more information can be found here: https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types
    type: ClusterIP
    # This sets the ports more information can be found here: https://kubernetes.io/docs/concepts/services-networking/service/#field-spec-ports
    port: 3000

  # This block is for setting up the ingress for more information can be found here: https://kubernetes.io/docs/concepts/services-networking/ingress/
  ingress:
    enabled: false
    className: ""
    annotations: {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  resources:
    limits:
      cpu: 1000m
      memory: 1Gi
    requests:
      cpu: 250m
      memory: 256Mi
  # This is to setup the liveness and readiness probes more information can be found here: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  livenessProbe:
    httpGet:
      path: /
      port: http
  readinessProbe:
    httpGet:
      path: /
      port: http
  # Startup probe for UI (Next.js build/startup can take 10-30s)
  # Example:
  #   startupProbe:
  #     httpGet:
  #       path: /
  #       port: http
  #     failureThreshold: 30
  #     periodSeconds: 10
  startupProbe: {}

  # This section is for setting up autoscaling more information can be found here: https://kubernetes.io/docs/concepts/workloads/autoscaling/
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 100
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80

  # Additional volumes on the output Deployment definition.
  volumes: []
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # Additional volumeMounts on the output Deployment definition.
  volumeMounts: []
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  nodeSelector: {}

  tolerations: []

  affinity: {}

  # Spread UI pods across nodes to survive single-node failures.
  # When true, generates a soft (ScheduleAnyway) TopologySpreadConstraint
  # keyed on kubernetes.io/hostname with the correct label selector.
  defaultTopologySpread: true
  # Override with custom topology spread constraints (takes precedence over defaultTopologySpread)
  topologySpreadConstraints: []

  # Extra environment variables to add to UI pods.
  # Example:
  #   extraEnv:
  #     - name: MY_VAR
  #       value: "my-value"
  #     - name: MY_SECRET
  #       valueFrom:
  #         secretKeyRef:
  #           name: my-secret
  #           key: password
  extraEnv: []

  # Extra envFrom sources to add to UI pods.
  # Example:
  #   extraEnvFrom:
  #     - configMapRef:
  #         name: my-extra-config
  #     - secretRef:
  #         name: my-extra-secret
  extraEnvFrom: []

  # Network policy configuration
  networkPolicy:
    enabled: false
    # Additional ingress rules
    ingress: []
    # Additional egress rules
    egress: []

api:
  # This will set the replicaset count more information can be found here: https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/
  replicaCount: 2

  # Time in seconds to allow the API pod to gracefully shut down.
  # The API server (gunicorn) needs time to finish serving in-flight HTTP requests
  # before terminating. The default of 30s is appropriate for most deployments.
  terminationGracePeriodSeconds: 30

  # Pod Disruption Budget - ensures high availability during voluntary disruptions
  # More info: https://kubernetes.io/docs/tasks/run-application/configure-pdb/
  podDisruptionBudget:
    enabled: true
    minAvailable: 1
    # maxUnavailable: 1

  # This sets the container image more information can be found here: https://kubernetes.io/docs/concepts/containers/images/
  image:
    repository: prowlercloud/prowler-api
    # This sets the pull policy for images.
    pullPolicy: IfNotPresent
    # Overrides the image tag whose default is the chart appVersion.
    tag: ""
    # Immutable image reference. When set, takes precedence over tag.
    # Example: sha256:abc123...
    digest: ""

  # Network policy configuration
  networkPolicy:
    enabled: false
    # Port used for PostgreSQL egress rules (must match your external PostgreSQL instance)
    postgresPort: 5432
    # Port used for Valkey/Redis egress rules (must match your external Valkey instance)
    valkeyPort: 6379
    # Additional ingress rules
    ingress: []
    # Additional egress rules
    egress: []

  # Shared with celery-worker and celery-beat
  djangoConfig:
    # API scan settings
    # The path to the directory where scan output should be stored
    DJANGO_TMP_OUTPUT_DIRECTORY: "/tmp/prowler_api_output"
    # The maximum number of findings to process in a single batch
    DJANGO_FINDINGS_BATCH_SIZE: "1000"
    # The maximum number of items to delete in a single batch operation
    DJANGO_DELETION_BATCH_SIZE: "1000"
    # SECURITY: Wildcard allows any Host header. In production, restrict to your actual
    # domain(s) to prevent Host header injection attacks:
    #   DJANGO_ALLOWED_HOSTS: "prowler.example.com,prowler-api.prowler.svc.cluster.local"
    # Note: Internal service names must be included for pod-to-pod communication.
    DJANGO_ALLOWED_HOSTS: "*"
    DJANGO_BIND_ADDRESS: "0.0.0.0"
    DJANGO_PORT: "8080"
    DJANGO_DEBUG: "False"
    DJANGO_SETTINGS_MODULE: "config.django.production"
    # Select one of [ndjson|human_readable]
    DJANGO_LOGGING_FORMATTER: "ndjson"
    # Select one of [DEBUG|INFO|WARNING|ERROR|CRITICAL]
    # Applies to both Django and Celery Workers
    DJANGO_LOGGING_LEVEL: "INFO"
    # Defaults to the maximum available based on CPU cores if not set.
    DJANGO_WORKERS: "4"
    # Token lifetime is in minutes
    DJANGO_ACCESS_TOKEN_LIFETIME: "30"
    # Token lifetime is in minutes
    DJANGO_REFRESH_TOKEN_LIFETIME: "1440"
    # Throttle limit for token obtain endpoint (requests per hour)
    DJANGO_THROTTLE_TOKEN_OBTAIN: "10/hour"
    DJANGO_CACHE_MAX_AGE: "3600"
    DJANGO_STALE_WHILE_REVALIDATE: "60"
    DJANGO_MANAGE_DB_PARTITIONS: "True"
    DJANGO_BROKER_VISIBILITY_TIMEOUT: "86400"
    # Maximum number of celery deadlock detection attempts
    DJANGO_CELERY_DEADLOCK_ATTEMPTS: "5"
    # Optional Sentry configuration for error tracking
    # DJANGO_SENTRY_DSN: ""
    # SENTRY_ENVIRONMENT: "production"
    # SENTRY_RELEASE: ""
    # Optional OAuth configuration - Google
    # GOOGLE_OAUTH_CLIENT_ID: ""
    # GOOGLE_OAUTH_CLIENT_SECRET: ""
    # GOOGLE_OAUTH_CALLBACK_URL: ""
    # Optional OAuth configuration - GitHub
    # GITHUB_OAUTH_CLIENT_ID: ""
    # GITHUB_OAUTH_CLIENT_SECRET: ""
    # GITHUB_OAUTH_CALLBACK_URL: ""
  djangoConfigKeys:
    # Create secret with Django JWT signing keys and encryption key.
    # Uses the Prowler API image (no external image dependency).
    # Keys are generated on first install and preserved across upgrades.
    #
    # For production, generate keys manually and set create: false:
    #   openssl genrsa -out private.pem 2048
    #   openssl rsa -in private.pem -pubout -out public.pem
    #   kubectl create secret generic <release>-api-django-config-keys \
    #     --from-file=DJANGO_TOKEN_SIGNING_KEY=private.pem \
    #     --from-file=DJANGO_TOKEN_VERIFYING_KEY=public.pem \
    #     --from-literal=DJANGO_SECRETS_ENCRYPTION_KEY=$(openssl rand -base64 32)
    create: true

  # Secret names to be used as env vars.
  secrets: []
    # - "prowler-api-keys"

  command:
    - /home/prowler/docker-entrypoint.sh
  args:
    - prod

  # This is for the secrets for pulling an image from a private repository more information can be found here: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
  imagePullSecrets: []

  # This section builds out the service account more information can be found here: https://kubernetes.io/docs/concepts/security/service-accounts/
  serviceAccount:
    # Specifies whether a service account should be created
    create: true
    # Automatically mount a ServiceAccount's API credentials?
    automount: true
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: ""

  # This is for setting Kubernetes Annotations to a Pod.
  # For more information checkout: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  podAnnotations: {}
  # This is for setting Kubernetes Labels to a Pod.
  # For more information checkout: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  podLabels: {}

  podSecurityContext:
    runAsNonRoot: true
    runAsUser: 1000
    fsGroup: 1000
    seccompProfile:
      type: RuntimeDefault

  securityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: false  # API needs write access to DJANGO_TMP_OUTPUT_DIRECTORY
    runAsNonRoot: true
    runAsUser: 1000
    capabilities:
      drop:
        - ALL

  # This is for setting up a service more information can be found here: https://kubernetes.io/docs/concepts/services-networking/service/
  service:
    # This sets the service type more information can be found here: https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types
    type: ClusterIP
    # This sets the ports more information can be found here: https://kubernetes.io/docs/concepts/services-networking/service/#field-spec-ports
    port: 8080

  # This block is for setting up the ingress for more information can be found here: https://kubernetes.io/docs/concepts/services-networking/ingress/
  ingress:
    enabled: false
    className: ""
    annotations: {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  resources:
    limits:
      cpu: 2000m
      memory: 2Gi
    requests:
      cpu: 500m
      memory: 512Mi
  # This is to setup the startup, liveness and readiness probes more information can be found here: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  # Startup probe is useful for slow starting containers (DB migrations can take 3-4 minutes)
  startupProbe:
    httpGet:
      path: /api/v1/docs
      port: http
    failureThreshold: 30
    periodSeconds: 10
    # Total startup time: 30 * 10s = 5 minutes
  livenessProbe:
    failureThreshold: 10
    httpGet:
      path: /api/v1/docs
      port: http
    periodSeconds: 20
  readinessProbe:
    failureThreshold: 10
    httpGet:
      path: /api/v1/docs
      port: http
    periodSeconds: 20

  # This section is for setting up autoscaling more information can be found here: https://kubernetes.io/docs/concepts/workloads/autoscaling/
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 100
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80

  # Optional persistent storage for API configuration directory
  # This stores Prowler API configuration files at /home/prowler/.config/prowler-api
  configStorage:
    enabled: false
    # Type: emptyDir or persistentVolumeClaim
    type: persistentVolumeClaim
    # Configuration for emptyDir type
    emptyDir:
      medium: ""
      sizeLimit: ""
    # Configuration for persistentVolumeClaim type
    persistentVolumeClaim:
      create: true
      existingClaim: ""
      storageClassName: ""
      accessMode: ReadWriteOnce
      size: 1Gi

  # Additional volumes on the output Deployment definition.
  volumes: []
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # Additional volumeMounts on the output Deployment definition.
  volumeMounts: []
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  nodeSelector: {}

  tolerations: []

  affinity: {}

  # Spread API pods across nodes to survive single-node failures.
  defaultTopologySpread: true
  topologySpreadConstraints: []

  # Extra environment variables to add to API pods.
  # Useful for per-component overrides (e.g., DJANGO_WORKERS on API only).
  # Example:
  #   extraEnv:
  #     - name: MY_VAR
  #       value: "my-value"
  #     - name: MY_SECRET
  #       valueFrom:
  #         secretKeyRef:
  #           name: my-secret
  #           key: password
  extraEnv: []

  # Extra envFrom sources to add to API pods.
  # Example:
  #   extraEnvFrom:
  #     - configMapRef:
  #         name: my-extra-config
  #     - secretRef:
  #         name: my-extra-secret
  extraEnvFrom: []

worker:
  # This will set the replicaset count more information can be found here: https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/
  replicaCount: 2

  # Time in seconds to allow worker pods to gracefully shut down before being killed.
  # This gives in-flight scans time to complete during voluntary disruptions
  # (e.g., Karpenter consolidation, rolling updates).
  terminationGracePeriodSeconds: 300

  # Pod Disruption Budget - ensures high availability during voluntary disruptions
  # More info: https://kubernetes.io/docs/tasks/run-application/configure-pdb/
  podDisruptionBudget:
    enabled: true
    minAvailable: 1
    # maxUnavailable: 1

  # This sets the container image more information can be found here: https://kubernetes.io/docs/concepts/containers/images/
  image:
    repository: prowlercloud/prowler-api
    # This sets the pull policy for images.
    pullPolicy: IfNotPresent
    # Overrides the image tag whose default is the chart appVersion.
    tag: ""
    # Immutable image reference. When set, takes precedence over tag.
    # Example: sha256:abc123...
    digest: ""

  # Number of concurrent Celery worker processes (prefork pool size).
  #
  # When set to a positive integer, the chart bypasses the docker-entrypoint.sh and
  # invokes Celery directly with --concurrency N. This is necessary because the
  # Prowler entrypoint hardcodes the celery command and ignores extra arguments.
  #
  # When set to null, the entrypoint runs unchanged and Celery defaults to
  # multiprocessing.cpu_count() — the NODE CPU count, NOT the container CPU limit.
  # A pod on a 16-core node spawns 16 workers regardless of CPU limits.
  #
  # Each Prowler scan task uses ~1-1.5 GiB peak memory. Size limits accordingly:
  #   concurrency: 1 -> limits.memory: 2Gi
  #   concurrency: 2 -> limits.memory: 4Gi  (default)
  #   concurrency: 4 -> limits.memory: 8Gi  (requires nodes with 16+ GiB RAM)
  #
  # When upstream Prowler adds native CELERY_WORKER_CONCURRENCY env var support,
  # this value will be deprecated in favor of the env var approach via extraEnv.
  concurrency: 2

  # Celery queue list the worker consumes from.
  # Only used when worker.concurrency is set (bypasses the entrypoint).
  # Must match the queues in the Prowler docker-entrypoint.sh.
  queues: "celery,scans,scan-reports,deletion,backfill,overview,integrations,compliance,attack-paths-scans"

  # Override command/args when you need full control (e.g., custom entrypoint).
  # When worker.concurrency is set, these are ignored — the chart constructs the
  # celery command automatically. Set concurrency to null to use these values.
  command:
    - /home/prowler/docker-entrypoint.sh
  args:
    - worker

  # Container lifecycle hooks.
  # Use preStop to ensure Celery workers finish in-flight tasks before SIGTERM.
  #
  # How Celery worker shutdown works:
  #   1. Kubernetes sends SIGTERM to the container
  #   2. Celery enters "warm shutdown" -- stops accepting new tasks, finishes current ones
  #   3. If tasks don't finish within terminationGracePeriodSeconds, SIGKILL is sent
  #
  # IMPORTANT: Prowler uses acks_late=False by default (verify with your version).
  # This means tasks are ACKed on receipt, NOT on completion. If a worker is killed
  # mid-scan, the task is NOT retried -- the scan recovery mechanism handles this.
  #
  # The preStop hook adds a small delay before SIGTERM to allow the pod to be removed
  # from Service endpoints first (prevents new connections during shutdown).
  #
  # Example:
  #   lifecycle:
  #     preStop:
  #       exec:
  #         command: ["/bin/sh", "-c", "sleep 15"]
  #
  # Tune terminationGracePeriodSeconds to match your longest expected scan duration.
  # Default is 300s (5 minutes). For long-running scans, increase accordingly.
  lifecycle: {}

  # This is for the secrets for pulling an image from a private repository more information can be found here: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
  imagePullSecrets: []

  # This section builds out the service account more information can be found here: https://kubernetes.io/docs/concepts/security/service-accounts/
  serviceAccount:
    # Specifies whether a service account should be created
    create: true
    # Automatically mount a ServiceAccount's API credentials?
    automount: true
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: ""

  # RBAC configuration for Kubernetes scanning
  # The Worker pods execute K8s provider scans and need cluster-wide read access.
  # The API server does NOT need these permissions.
  rbac:
    # Create ClusterRole and ClusterRoleBinding for Kubernetes resource scanning
    # Set to false if you don't plan to scan Kubernetes resources
    create: true
    # Additional RBAC rules to append to the default set
    rules: []

  # This is for setting Kubernetes Annotations to a Pod.
  # For more information checkout: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  podAnnotations: {}
  # This is for setting Kubernetes Labels to a Pod.
  # For more information checkout: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  podLabels: {}

  podSecurityContext:
    runAsNonRoot: true
    runAsUser: 1000
    fsGroup: 1000
    seccompProfile:
      type: RuntimeDefault

  securityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: false  # Worker needs write access for scan outputs
    runAsNonRoot: true
    runAsUser: 1000
    capabilities:
      drop:
        - ALL

  resources:
    limits:
      cpu: 2000m
      memory: 4Gi
    requests:
      cpu: 500m
      memory: 2Gi
  # Health probes for Celery workers
  # More info: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  #
  # NOTE: The Prowler API image does NOT include pgrep, ps, or celery in PATH.
  # The celery binary is inside a poetry virtualenv whose path may change between versions.
  # Use /proc-based checks for reliable probes.
  #
  # Recommended approach (checks entrypoint process contains "worker"):
  #   livenessProbe:
  #     exec:
  #       command: ["/bin/sh", "-c", "grep -q worker /proc/1/cmdline"]
  #     periodSeconds: 60
  #     failureThreshold: 3
  #   readinessProbe:
  #     exec:
  #       command: ["/bin/sh", "-c", "grep -q worker /proc/1/cmdline"]
  #     periodSeconds: 30
  #     failureThreshold: 3
  #   startupProbe:
  #     exec:
  #       command: ["/bin/sh", "-c", "grep -q worker /proc/1/cmdline"]
  #     failureThreshold: 30
  #     periodSeconds: 10
  livenessProbe: {}
  readinessProbe: {}
  startupProbe: {}

  # This section is for setting up autoscaling more information can be found here: https://kubernetes.io/docs/concepts/workloads/autoscaling/
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 10
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80

  # Additional volumes on the output Deployment definition.
  volumes: []
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # Additional volumeMounts on the output Deployment definition.
  volumeMounts: []
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  nodeSelector: {}

  tolerations: []

  affinity: {}

  # Spread worker pods across nodes so a single-node eviction doesn't kill all workers.
  # Critical for Karpenter environments where node consolidation can evict entire workloads.
  defaultTopologySpread: true
  topologySpreadConstraints: []

  # Extra environment variables to add to worker pods.
  # Useful for per-component overrides.
  # Example:
  #   extraEnv:
  #     - name: MY_VAR
  #       value: "my-value"
  #     - name: MY_SECRET
  #       valueFrom:
  #         secretKeyRef:
  #           name: my-secret
  #           key: password
  extraEnv: []

  # Extra envFrom sources to add to worker pods.
  # Example:
  #   extraEnvFrom:
  #     - configMapRef:
  #         name: my-extra-config
  #     - secretRef:
  #         name: my-extra-secret
  extraEnvFrom: []

  # Network policy configuration
  networkPolicy:
    enabled: false
    # Port used for PostgreSQL egress rules (must match your external PostgreSQL instance)
    postgresPort: 5432
    # Port used for Valkey/Redis egress rules (must match your external Valkey instance)
    valkeyPort: 6379
    # Additional egress rules
    egress: []

  # Scan recovery init container configuration.
  # Recovers orphaned scans stuck in "executing" state after worker pod eviction.
  # Runs as an init container before the Celery worker starts.
  scanRecovery:
    enabled: true
    # Grace period in seconds — scans executing for less than this duration
    # are considered still in-flight and will not be recovered.
    # Set to 0 to recover all executing scans regardless of age.
    gracePeriodSeconds: 600

  # Periodic scan recovery CronJob configuration.
  # Uses a time-based threshold to find and fail scans that have been
  # in "executing" state for too long, without requiring a worker restart.
  scanRecoveryCronJob:
    enabled: false
    # Cron schedule expression (default: every 15 minutes)
    schedule: "*/15 * * * *"
    # Scans executing longer than this threshold (seconds) are considered stuck
    thresholdSeconds: 7200
    # Kubernetes concurrency policy — Forbid prevents overlapping jobs
    concurrencyPolicy: Forbid
    # Number of successful/failed jobs to retain for debugging
    successfulJobsHistoryLimit: 3
    failedJobsHistoryLimit: 3
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 100m
        memory: 256Mi
    # ServiceAccount for the CronJob.
    # By default, creates a dedicated SA without cloud scanning IAM privileges.
    # Set create: false and name: "" to fall back to the worker ServiceAccount (not recommended).
    serviceAccount:
      create: true
      # Do not mount K8s API token -- CronJob only needs PostgreSQL access
      automount: false
      annotations: {}
      # Override the auto-generated name
      name: ""

worker_beat:
  # IMPORTANT: Celery Beat must run as a singleton (exactly one replica).
  # Running multiple beat instances causes duplicate task scheduling.
  # The deployment uses strategy: Recreate to prevent overlap during upgrades.
  replicaCount: 1

  # Time in seconds to allow beat pod to gracefully shut down.
  # Beat does not process long-running tasks, so the default K8s value (30s) is usually fine.
  terminationGracePeriodSeconds: 30

  # Pod Disruption Budget - for beat worker, we ensure at least 0 are available
  # (since only 1 should run at a time, but we want controlled disruption)
  # More info: https://kubernetes.io/docs/tasks/run-application/configure-pdb/
  podDisruptionBudget:
    enabled: false
    minAvailable: 0
    # maxUnavailable: 1

  # This sets the container image more information can be found here: https://kubernetes.io/docs/concepts/containers/images/
  image:
    repository: prowlercloud/prowler-api
    # This sets the pull policy for images.
    pullPolicy: IfNotPresent
    # Overrides the image tag whose default is the chart appVersion.
    tag: ""
    # Immutable image reference. When set, takes precedence over tag.
    # Example: sha256:abc123...
    digest: ""

  command:
    - /home/prowler/docker-entrypoint.sh
  args:
    - beat

  # This is for the secrets for pulling an image from a private repository more information can be found here: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
  imagePullSecrets: []

  # This section builds out the service account more information can be found here: https://kubernetes.io/docs/concepts/security/service-accounts/
  serviceAccount:
    # Specifies whether a service account should be created
    create: true
    # Beat scheduler does not need Kubernetes API access.
    # Set to true only if using Pod Identity webhook that requires projected tokens.
    automount: false
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: ""

  # This is for setting Kubernetes Annotations to a Pod.
  # For more information checkout: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  podAnnotations: {}
  # This is for setting Kubernetes Labels to a Pod.
  # For more information checkout: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  podLabels: {}

  podSecurityContext:
    runAsNonRoot: true
    runAsUser: 1000
    fsGroup: 1000
    seccompProfile:
      type: RuntimeDefault

  securityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: false  # Beat worker needs write access for scheduling state
    runAsNonRoot: true
    runAsUser: 1000
    capabilities:
      drop:
        - ALL

  resources:
    limits:
      cpu: 500m
      memory: 512Mi
    requests:
      cpu: 100m
      memory: 128Mi
  # Health probes for Celery Beat scheduler
  # More info: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  #
  # WARNING: The commonly suggested "celery inspect ping" does NOT verify beat --
  # it pings workers via the broker. If workers respond but beat is dead, the probe passes.
  # A reliable beat probe must check something beat-specific.
  #
  # NOTE: The Prowler API image does NOT include pgrep or ps. Use /proc-based checks instead.
  #
  # Recommended approach (checks entrypoint process contains "beat"):
  #   livenessProbe:
  #     exec:
  #       command: ["/bin/sh", "-c", "grep -q beat /proc/1/cmdline"]
  #     periodSeconds: 60
  #     failureThreshold: 3
  #   readinessProbe:
  #     exec:
  #       command: ["/bin/sh", "-c", "grep -q beat /proc/1/cmdline"]
  #     periodSeconds: 30
  #     failureThreshold: 3
  #   startupProbe:
  #     exec:
  #       command: ["/bin/sh", "-c", "grep -q beat /proc/1/cmdline"]
  #     failureThreshold: 30
  #     periodSeconds: 10
  #
  # Alternative if Prowler's beat writes a schedule file:
  #   livenessProbe:
  #     exec:
  #       command:
  #         - /bin/sh
  #         - -c
  #         - |
  #           # Fail if schedule file hasn't been touched in 5 minutes
  #           find /tmp -name 'celerybeat-schedule' -mmin -5 | grep -q .
  #     periodSeconds: 60
  #     failureThreshold: 3
  livenessProbe: {}
  readinessProbe: {}
  startupProbe: {}

  # Additional volumes on the output Deployment definition.
  volumes: []
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # Additional volumeMounts on the output Deployment definition.
  volumeMounts: []
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  nodeSelector: {}

  tolerations: []

  affinity: {}

  # Custom topology spread constraints (single replica, so no default spread)
  topologySpreadConstraints: []

  # Extra environment variables to add to worker-beat pods.
  # Useful for per-component overrides.
  # Example:
  #   extraEnv:
  #     - name: MY_VAR
  #       value: "my-value"
  #     - name: MY_SECRET
  #       valueFrom:
  #         secretKeyRef:
  #           name: my-secret
  #           key: password
  extraEnv: []

  # Extra envFrom sources to add to worker-beat pods.
  # Example:
  #   extraEnvFrom:
  #     - configMapRef:
  #         name: my-extra-config
  #     - secretRef:
  #         name: my-extra-secret
  extraEnvFrom: []

  # Network policy configuration
  networkPolicy:
    enabled: false
    # Port used for PostgreSQL egress rules (must match your external PostgreSQL instance)
    postgresPort: 5432
    # Port used for Valkey/Redis egress rules (must match your external Valkey instance)
    valkeyPort: 6379
    # Additional egress rules
    egress: []

# Neo4j (DozerDB) configuration for Attack Paths feature (Prowler 5.17+)
# DozerDB is a Neo4j-compatible database optimized for Prowler
neo4j:
  # Enable/disable Neo4j deployment
  # Required for Prowler 5.17+ Attack Paths feature
  enabled: true

  # Container image configuration
  image:
    repository: graphstack/dozerdb
    tag: "5.26.3.0"
    pullPolicy: IfNotPresent
    # Immutable image reference. When set, takes precedence over tag.
    # Example: sha256:abc123...
    digest: ""

  # Authentication configuration
  auth:
    username: neo4j
    # Password is auto-generated if not provided
    # To set your own: --set neo4j.auth.password=yourpassword
    # Auto-generated password is preserved across upgrades
    password: ""

  # DozerDB configuration
  # DozerDB is a Neo4j fork that uses the legacy dbms.* env var prefix.
  # Memory settings map to dbms.memory.* (NOT server.memory.* as in vanilla Neo4j 5.x).
  # DozerDB does NOT support dbms.default_database or dbms.max_databases env vars.
  # Use extraEnv below to pass any additional DozerDB-specific settings.
  config:
    # Page cache size (dbms.memory.pagecache.size)
    pagecacheSize: "1G"
    # Initial JVM heap size (dbms.memory.heap.initial_size)
    heapInitialSize: "1G"
    # Maximum JVM heap size (dbms.memory.heap.max_size)
    heapMaxSize: "1G"

  # Service configuration
  service:
    type: ClusterIP
    # Bolt protocol port (used by Prowler)
    port: 7687
    # HTTP port (for Neo4j Browser, optional)
    httpPort: 7474

  # Persistence configuration
  persistence:
    # Enable persistent storage for Neo4j data
    # Enabled by default for data durability
    enabled: true
    # Storage size
    size: 10Gi
    # Storage class (leave empty for default)
    storageClass: ""
    # Access mode
    accessMode: ReadWriteOnce

  # Startup, liveness and readiness probes
  # More info: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  startupProbe:
    httpGet:
      path: /
      port: http
    failureThreshold: 30
    periodSeconds: 10
    timeoutSeconds: 5
  livenessProbe:
    httpGet:
      path: /
      port: http
    periodSeconds: 20
    failureThreshold: 3
    timeoutSeconds: 5
  readinessProbe:
    httpGet:
      path: /
      port: http
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 5

  # Resource requests and limits
  resources:
    requests:
      memory: "2Gi"
      cpu: "500m"
    limits:
      memory: "4Gi"
      cpu: "2000m"

  # Pod security context
  podSecurityContext:
    runAsNonRoot: true
    runAsUser: 7474
    fsGroup: 7474
    seccompProfile:
      type: RuntimeDefault

  # Container security context
  securityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: false  # Neo4j needs write access to data directory
    runAsNonRoot: true
    runAsUser: 7474
    capabilities:
      drop:
        - ALL

  # This is for the secrets for pulling an image from a private repository
  imagePullSecrets: []

  # ServiceAccount for Neo4j
  serviceAccount:
    # Specifies whether a service account should be created
    create: true
    # Neo4j does not need Kubernetes API access
    automount: false
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: ""

  # Pod annotations
  podAnnotations: {}

  # Pod labels
  podLabels: {}

  # Grace period for Neo4j shutdown. Neo4j needs time to flush transactions and
  # close the store lock. Default 120s covers most index build and transaction scenarios.
  terminationGracePeriodSeconds: 120

  # Pod Disruption Budget - protects the RWO PVC singleton during voluntary disruptions.
  # In Karpenter environments, prevents eviction with insufficient grace period.
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
    # maxUnavailable: 0

  # Node selector
  nodeSelector: {}

  # Tolerations
  tolerations: []

  # Affinity rules
  affinity: {}

  # Network policy configuration
  networkPolicy:
    enabled: false
    # Additional ingress rules
    ingress: []

  # Additional environment variables to inject into the Neo4j container.
  # Useful for passing DozerDB-specific settings not covered by config above.
  # Example:
  #   extraEnv:
  #     - name: NEO4J_dbms_tx__log_rotation_retention__policy
  #       value: "2 days"
  extraEnv: []

  # Additional envFrom sources (ConfigMapRef, SecretRef) for the Neo4j container.
  # Example:
  #   extraEnvFrom:
  #     - secretRef:
  #         name: my-neo4j-secrets
  extraEnvFrom: []
